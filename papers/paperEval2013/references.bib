@article{Delcher2002,
  author = {Delcher, A L and Phillippy, A and Carlton, J and Salzberg, S L},
  journal = {Nucleic Acids Research},
  pages = {2478--2483},
  title = {{MUMmer: comparative applications Fast algorithms for large-scale genome alignment and comparison}},
  url = {http://www.tigr.org/software/mummer/applications.html},
  volume = {30},
  year = {2002}
}
@article{Delcher2003,
  abstract = {The MUMmer sequence alignment package is a suite of computer programs designed to detect regions of homology in long biological sequences. Version 2.1 makes several improvements to the package, including: increased speed and reduced memory requirements; the ability to handle both protein and DNA sequences; the ability to handle multiple sequence fragments; and new algorithms for clustering together basic matches. The system is particularly efficient at comparing highly similar sequences, such as alternative versions of fragment assemblies or closely related strains of the same bacterium.},
  author = {Delcher, Arthur L and Salzberg, Steven L and Phillippy, Adam M},
  institution = {The Institute for Genomic Research Rockville, Maryland and Computer Science Department, Loyola College in Maryland, Baltimore, Maryland, USA.},
  journal = {Current protocols in bioinformatics editoral board Andreas D Baxevanis et al},
  keywords = {algorithms,automated,automated methods,chromosome mapping,chromosome mapping methods,pattern recognition,sequence alignment,sequence alignment methods,sequence analysis,sequence analysis methods,sequence homology,software},
  number = {1934-340X (Electronic) LA - eng PT - Journal Article SB - IM},
  pages = {Unit 10.3},
  pmid = {18428693},
  title = {{Using MUMmer to identify similar regions in large sequence sets.}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/18428693},
  volume = {Chapter 10},
  year = {2003}
}
@article{Delcher1999,
  author = {Delcher, A L and Kasif, S and Fleischmann, R D and Peterson, J and White, O and Salzberg, S L},
  journal = {Nucl Acids Res},
  number = {11},
  pages = {2369},
  publisher = {Oxford Univ Press},
  title = {{Alignment of whole genomes MUMMER}},
  volume = {27},
  year = {1999}
}

@article{OguzhanKulekci2011,
  abstract = {Genomic read alignment involves mapping (exactly or approximately) short reads from a particular individual onto a pre-sequenced reference genome of the same species. Because all individuals of the same species share the majority of their genomes, short reads alignment provides an alternative and much more efficient way to sequence the genome of a particular individual than does direct sequencing. Among many strategies proposed for this alignment process, indexing the reference genome and short read searching over the index is a dominant technique. Our goal is to design a space-efficient indexing structure with fast searching capability to catch the massive short reads produced by the next generation high-throughput DNA sequencing technology.},
  author = {{O\v{g}uzhan K\"{u}lekci}, M and Hon, Wing-Kai and Shah, Rahul and {Scott Vitter}, Jeffrey and Xu, Bojian},
  doi = {10.1186/1471-2164-12-S2-S7},
  issn = {1471-2164},
  journal = {BMC genomics},
  keywords = {Algorithms,Genome, Human,Genomics,Genomics: methods,High-Throughput Nucleotide Sequencing,High-Throughput Nucleotide Sequencing: methods,Humans,Sequence Alignment,Sequence Alignment: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
  month = jan,
  pages = {S7},
  pmid = {21989248},
  title = {{$\Psi$-RA: a parallel sparse index for genomic read alignment.}},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3194238\&tool=pmcentrez\&rendertype=abstract},
  volume = {12 Suppl 2},
  year = {2011}
}

@MISC{Mongelli,
  author = {Mongelli, H},
  file = {:media/garviz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mongelli - Unknown - Efficient Two-Dimensional Parallel Pattern Matching with Scaling.pdf:pdf},
  journal = {North},
  keywords = {2,coarse-grained multicomputer,matching with scaling,parallel algorithms,pattern,some defini-,string matching with scaling,the computing model and},
  title = {{Efficient Two-Dimensional Parallel Pattern Matching with Scaling}},
  year = {}
}

@article{Kouzinopoulos2005,
  author = {Kouzinopoulos, Charalampos S and Michailidis, Panagiotis D and Margaritis, Konstantinos G},
  journal = {Systems and Computational Biology - Bioinformatics and Computational Modeling},
  title = {Parallel Processing of Multiple Pattern Matching Algorithms for Biological Sequences : Methods and Performance Results},
  year = {2005}
}

@article{Meng2005,
  author = {Meng, Xiandong and Chaudhary, V.},
  file = {:media/garviz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng, Chaudhary - 2005 - Exploiting multi-level parallelism for homology search using general purpose processors.pdf:pdf},
  isbn = {0769522815},
  journal = {October},
  publisher = {IEEE Computer Society},
  title = {{Exploiting multi-level parallelism for homology search using general purpose processors}},
  url = {http://www.computer.org/portal/web/csdl/doi/10.1109/ICPADS.2005.152},
  year = {2005}
}

@article{Encarnac2011,
  author = {Encarnac, Gustavo and Roma, Nuno},
  file = {:media/garviz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Encarnac, Roma - 2011 - Advantages and GPU Implementation of High-Performance Indexed DNA Search based on Suffix Arrays.pdf:pdf},
  isbn = {9781612843834},
  journal = {Architecture},
  keywords = {10 9 base pairs,bioinformatics,ex-,for large sequences,genome,gpgpu,indexed search,other sub-,runtime,such as the human,this runtime can be,to the development of,tremely large which led,with about 3},
  pages = {49--55},
  title = {{Advantages and GPU Implementation of High-Performance Indexed DNA Search based on Suffix Arrays}},
  year = {2011}
}

@article{Vyverman2013,
abstract = {SUMMARY: We have developed essaMEM, a tool for finding maximal exact matches that can be used in genome comparison and read mapping. essaMEM enhances an existing sparse suffix array implementation with a sparse child array. Tests indicate that the enhanced algorithm for finding maximal exact matches is much faster, while maintaining the same memory footprint. In this way, sparse suffix arrays remain competitive with the more complex compressed suffix arrays. AVAILABILITY: Source code is freely available at https://github.ugent.be/ComputationalBiology/essaMEM. CONTACT: Michael.Vyverman@UGent.be SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
author = {Vyverman, Micha\"{e}l and {De Baets}, Bernard and Fack, Veerle and Dawyndt, Peter},
doi = {10.1093/bioinformatics/btt042},
file = {:media/garviz/Escritorio/Bioinformatics-2013-Vyverman-bioinformatics\_btt042.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
month = feb,
pages = {2--4},
pmid = {23349213},
title = {{essaMEM: finding maximal exact matches using enhanced sparse suffix arrays.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23349213},
year = {2013}
}

@article{Khan2009,
abstract = {Motivation: High-throughput sequencing technologies place ever increasing demands on existing algorithms for sequence analysis. Algorithms for computing maximal exact matches (MEMs) between sequences appear in two contexts where high-throughput sequencing will vastly increase the volume of sequence data: (i) seeding alignments of high-throughput reads for genome assembly and (ii) designating anchor points for genome–genome comparisons.Results: We introduce a new algorithm for finding MEMs. The algorithm leverages a sparse suffix array (SA), a text index that stores every K-th position of the text. In contrast to a full text index that stores every position of the text, a sparse SA occupies much less memory. Even though we use a sparse index, the output of our algorithm is the same as a full text index algorithm as long as the space between the indexed suffixes is not greater than a minimum length of a MEM. By relying on partial matches and additional text scanning between indexed positions, the algorithm trades memory for extra computation. The reduced memory usage makes it possible to determine MEMs between significantly longer sequences.Availability: Source code for the algorithm is available under a BSD open source license at http://compbio.cs.princeton.edu/mems. The implementation can serve as a drop-in replacement for the MEMs algorithm in MUMmer 3.Contact: zkhan@cs.princeton.edu;mona@cs.princeton.eduSupplementary information: Supplementary data are available at Bioinformatics online. },
annote = {10.1093/bioinformatics/btp275 },
author = {Khan, Zia and Bloom, Joshua S and Kruglyak, Leonid and Singh, Mona},
doi = {10.1093/bioinformatics/btp275 },
journal = {Bioinformatics },
month = jul,
number = {13 },
pages = {1609--1616},
title = {{A practical algorithm for finding maximal exact matches in large sequence datasets using sparse suffix arrays}},
url = {http://bioinformatics.oxfordjournals.org/content/25/13/1609.abstract},
volume = {25 },
year = {2009}
}


@book{Gusfield1997,
abstract = {Traditionally an area of study in computer science, string algorithms have, in recent years, become an increasingly important part of biology, particularly genetics. This volume is a comprehensive look at computer algorithms for string processing. In addition to pure computer science, Gusfield adds extensive discussions on biological problems that are cast as string problems and on methods developed to solve them. This text emphasizes the fundamental ideas and techniques central to today's applications. New approaches to this complex material simplify methods that up to now have been for the specialist alone. With over 400 exercises to reinforce the material and develop additional topics, the book is suitable as a text for graduate or advanced undergraduate students in computer science, computational biology, or bio-informatics.},
author = {Gusfield, Dan},
booktitle = {Theory and Practice},
doi = {10.1016/S0097-8485(00)80014-5},
isbn = {0521585198},
issn = {00978485},
pages = {554},
publisher = {Cambridge University Press},
title = {{Algorithms on strings, trees, and sequences: computer science and computational biology}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521585198},
year = {1997}
}

@article{Abouelhoda2004,
author = {Abouelhoda, Mohamed Ibrahim and Kurtz, Stefan and Ohlebusch, Enno},
doi = {10.1016/S1570-8667(03)00065-0},
file = {:media/garviz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abouelhoda, Kurtz, Ohlebusch - 2004 - Replacing suffix trees with enhanced suffix arrays(2).pdf:pdf},
issn = {15708667},
journal = {Journal of Discrete Algorithms},
month = mar,
number = {1},
pages = {53--86},
title = {{Replacing suffix trees with enhanced suffix arrays}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1570866703000650},
volume = {2},
year = {2004}
}

@inproceedings{OhlebuschGK10,
  author    = {Enno Ohlebusch and
               Simon Gog and
               Adrian K{\"u}gel},
  title     = {Computing Matching Statistics and Maximal Exact Matches
               on Compressed Full-Text Indexes},
  booktitle = {SPIRE},
  year      = {2010},
  pages     = {347-358},
  ee        = {http://dx.doi.org/10.1007/978-3-642-16321-0_36},
}

@article{Chang1991,
author = {Chang, WI and Lawler, EL},
file = {:home/garviz/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang, Lawler - 1991 - Sublinear expected time approximate string matching and biological applications.pdf:pdf},
journal = {Algorithmica}, 
title = {{Sublinear expected time approximate string matching and biological applications}},
url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/1991/CSD-91-654.pdf},
year = {1991}
}

@article{Kurtz1999,
author = {Kurtz, Stefan},
file = {:Users/garviz/Library/Application Support/Mendeley Desktop/Downloaded/Kurtz - 1999 - Reducing the Space Requirement of Suffix Trees.pdf:pdf},
keywords = {data structures,implementation techniques,space reduction,suffix trees},
number = {February},
pages = {1149--1171},
title = {{Reducing the Space Requirement of Suffix Trees}},
journal = {Software – Practice and Experience},
volume = {29},
year = {1999}
}

@article{Kim2010,
abstract = {In-memory tree structured index search is a fundamental database operation. Modern processors provide tremendous computing power by integrating multiple cores, each with wide vector units. There has been much work to exploit modern processor architectures for database primitives like scan, sort, join and aggregation. However, unlike other primitives, tree search presents significant challenges due to irregular and unpredictable data accesses in tree traversal. In this paper, we present FAST, an extremely fast architecture sensitive layout of the index tree. FAST is a binary tree logically organized to optimize for architecture features like page size, cache line size, and SIMD width of the underlying hardware. FAST eliminates impact of memory latency, and exploits thread-level and datalevel parallelism on both CPUs and GPUs to achieve 50 million (CPU) and 85 million (GPU) queries per second, 5X (CPU) and 1.7X (GPU) faster than the best previously reported performance on the same architectures. FAST supports efficient bulk updates by rebuilding index trees in less than 0.1 seconds for datasets as large as 64Mkeys and naturally integrates compression techniques, overcoming the memory bandwidth bottleneck and achieving a 6X performance improvement over uncompressed index search for large keys on CPUs.},
author = {Kim, Changkyu and Chhugani, Jatin and Satish, Nadathur and Sedlar, Eric and Nguyen, Anthony D and Kaldewey, Tim and Lee, Victor W and Brandt, Scott A and Dubey, Pradeep},
doi = {10.1145/1807167.1807206},
isbn = {9781450300322},
journal = {Architecture},
pages = {339--350},
publisher = {ACM},
series = {SIGMOD '10},
title = {{FAST : Fast Architecture Sensitive Tree Search on Modern CPUs and GPUs}},
url = {http://portal.acm.org/citation.cfm?id=1807167.1807206},
year = {2010}
}

@article{Schatz2007,
abstract = {The recent availability of new, less expensive high-throughput DNA sequencing technologies has yielded a dramatic increase in the volume of sequence data that must be analyzed. These data are being generated for several purposes, including genotyping, genome resequencing, metagenomics, and de novo genome assembly projects. Sequence alignment programs such as MUMmer have proven essential for analysis of these data, but researchers will need ever faster, high-throughput alignment tools running on inexpensive hardware to keep up with new sequence technologies.},
author = {Schatz, Michael C and Trapnell, Cole and Delcher, Arthur L and Varshney, Amitabh},
doi = {10.1186/1471-2105-8-474},
file = {:home/garviz/Downloads/High-throughput sequence alignment using Graphics Processing.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Animals,Bacillus anthracis,Bacillus anthracis: genetics,Base Sequence,Caenorhabditis,Caenorhabditis: genetics,Computer Graphics,Computer Graphics: economics,Computer Graphics: instrumentation,Computers,Computers: economics,Contig Mapping,Contig Mapping: economics,Contig Mapping: instrumentation,DNA,DNA: ultrastructure,Database Management Systems,Databases, Genetic,Genomic Library,Listeria monocytogenes,Listeria monocytogenes: genetics,Sequence Alignment,Sequence Alignment: economics,Sequence Alignment: instrumentation,Sequence Alignment: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: economics,Sequence Analysis, DNA: instrumentation,Sequence Analysis, DNA: methods,Streptococcus suis,Streptococcus suis: genetics,Time Factors,Work Simplification},
month = jan,
pages = {474},
pmid = {18070356},
title = {{High-throughput sequence alignment using Graphics Processing Units.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2222658\&tool=pmcentrez\&rendertype=abstract},
volume = {8},
year = {2007}
}