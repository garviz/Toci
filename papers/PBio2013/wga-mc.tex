% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}
\usepackage[ruled,vlined]{algorithm2e}
\begin{document}

\title{Search for Maximal Unique Matches in Multi-core architectures}

\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
\alignauthor Julio C\'esar Garc\'ia Vizca\'ino\\
       \affaddr{Universitat Aut\`onoma de Barcelona\titlenote{Campus UAB, Edifici Q, 08193, Bellaterra (Barcelona), Spain}}\\
       \affaddr{Computer Architecture and Operating System}\\
       \email{juliocesar.garcia@caos.uab.es}
\alignauthor Juan Carlos Moure\\
       \affaddr{Universitat Aut\`onoma de Barcelona\titlenote{Campus UAB, Edifici Q, 08193, Bellaterra (Barcelona), Spain}}\\
       \affaddr{Computer Architecture and Operating System}\\
       \email{juancarlos.moure@uab.es}
\alignauthor Antonio Espinosa\\
       \affaddr{Universitat Aut\`onoma de Barcelona\titlenote{Campus UAB, Edifici Q, 08193, Bellaterra (Barcelona), Spain}}\\
       \affaddr{Computer Architecture and Operating System}\\
       \email{antonio.espinosa@caos.uab.es}
\and  % use '\and' if you need 'another row' of author names
\alignauthor Porf\'idio Hern\'andez\\
       \affaddr{Universitat Aut\`oonoma de Barcelona\titlenote{Campus UAB, Edifici Q, 08193, Bellaterra (Barcelona), Spain}}\\
       \affaddr{Computer Architecture and Operating System}\\
       \email{porfidio.hernandez@uab.es}
}

\date{22 March 2013}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
  Maximal Unique Matches are common substrings that match a reference and a query genome. They are exact, unique and maximal. The search of MUMs in large genomes is a heavy and repetitive task, so there is a fair chance of parallelize and execute this search in multi-core architectures. This research resembles an approach to find MUMs in genomic sequences and comparing the search in two data structures within multi-core architectures. The reference genome is indexed by using a Suffix Tree or Enhanced Suffix Array in main memory and then parallelized algorithm finds the MUMs of query genome which is readed by several threads in chunks of fixed size. This approach is based on MUMmer, a genome alignment tool, which is able to find Maximal Unique Matches (MUMs). 
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Algorithms, Experimentation, Performance, Theory}

\keywords{Indexed Search, Bioinformatics, Maximal Unique Match, Multi-core architectures, Parallelization}

\section{Introduction} 
Modern sequencing and computational technologies and advances in bioinformatics has made whole genome sequencing possible. One resulting challenge is the fast alignment of whole genomes. Dynamic programming is too slow for aligning two large genomes.\\
One very successful approach to perform whole genome alignment is based on identifying ``maximal unique matches'', which is based on the assumption that one expects to substrings occurring in two similar genomes.Maximal unique matches (MUMs) are almost surely part of a good alignment of the two sequences and so the whole genome alignment problem can be reduced to aligning the sequence in the gaps between the MUMs.
\newdef{definition}{Definition}
\begin{definition}
Assume we are given two sequences R,Q $\in \Sigma^*$, and a number L > 0. The maximal unique matches problem (MUM-problem) is to find all sequences u $\in \Sigma^*$ with: $|u|\geq L$, u occurs exactly once in R and once in Q, and for any character a $\in \Sigma^*$ neither ua nor au occurs both in R and Q.
\end{definition}
The problem of searching maximal unique matches for a minimum length between a reference string and a query string has been
identified in several applications, one of them is MUMmer \cite{Delcher2003}. MUMmer's algorithm can perform searches of maximal unique matches (MUMs), although
with a high use of main memory to store the reference string and a null use of multi-core architectures.

\section{Related work}
Search of Maximal Unique Matches to do Whole Genome Alignment was proposed in \cite{Delcher1999}. There have been some previous work in the parallelization of search of matches in genomic data, like \cite{OguzhanKulekci2011,Mongelli,Kouzinopoulos2005}, however these works are focused in fixed patterns and read alignment. On the other hand, there have been achievements in parallelization of Whole genome alignment like \cite{Meng2005}. The parallelization of searching MUMs with a full-text index data structure is a research field not covered very deep, there is only one approach in \cite{Encarnac2011} but without access to source code to check their implementation and it is more focused with GPU and CPU hybrid architectures and Suffix Array. There are other implementations to search Maximal exact matches with threads in \cite{Vyverman2013,OguzhanKulekci2011,Khan2009,OhlebuschGK10}
\section{Preliminaries}
Let's assume the reference string $R[0,\ldots, n − 1]$ of size n over an alphabet $\Sigma={ \$, A, C, G, T}$ which has a sentinel character $R[n − 1] = \$$ that occurs nowhere else in the string and is lexicographically less than all the characters that occur in the alphabet. The suffixes of the reference string are zero indexed by their position in the original string by a full-text index data structure like a Suffix Tree or a Suffix Array. 

\begin{definition}
A suffix Tree, $ST$, for an n-character string $R$ is a rooted directed tree with exactly $n$ leaves numbered 0 to n. Each internal node, other than the root, has at least two children and each edge is labeled with a nonempty substring of $R$. No two edges out of a node can have edge-labels beginning with the same character. For any leaf $i$, the concatenation of the edge-labels on the path from the root to leaf $i$ exactly spells out the suffix of $R$ that starts at position $i$. That is, it spells out $R[i\ldots n]$. \cite{Gusfield1997}.
\end{definition}
\begin{definition}
Given an n-character string $R$, a Suffix Array, $SA$, for $R$ is an array of the integers in the range 0 to $n$, specifying the lexicographic order of the $n$ suffixes of string $R$. \cite{Gusfield1997}.
\end{definition}
A search for a MUM between a Reference, $R$ of length $n$, and Query, $Q$ of length $m$, genome can be done in a Suffix Tree in $O(n+m)$ time and in a Suffix Array in $O(n\log m)$ time. However is possible to improve the search for MUMs algorithm in a Suffix Array by using: an inverse Suffix Array, a LCP-table and a child table. These improvements give a $O(m)$ time \cite{Abouelhoda2004} to search for MUMs in a Suffix Array.
\begin{definition}
An Inverse Suffix Array, $ISA$, is a table of size $n+1$ such that $ISA[SA[q]]=q$ for any $0\geq q\geq n$. \cite{Abouelhoda2004}.
\end{definition}
\begin{definition}
A LCP-table, $LCP$, is an array of integers from 0 to n. Where $LCP[0]=0$ and $LCP[i]$ is the length of the longest common prefix of $SA[i-i]$ and $SA[i]$ for $1\geq i \geq n$. \cite{Abouelhoda2004}.
\end{definition}
\begin{definition}
A child table, CHILD, is a table of size $n+1$ indexed from 0 to n and each entry contains three values: up, down, and nextlIndex. These values are defined as follows: 

CHILD[i].up = $min\{q\in [0\ldots i-1]|LCP[q]>LCP[i]\;and\;\\
\forall k\in[q+i\ldots i-1]:LCP[k]\geq LCP[q]\}$,

CHILD[i].down = $max\{q\in[i+1\ldots n]|LCP[q]>LCP[i]\\
and\;\forall k\in[i+1\ldots q-1]:LCP[k]\geq LCP[q]\}$,

CHILD[i].nextlIndex = $min\{q\in[i+1\ldots n]|LCP[q]=LCP[i]\\
and\;\forall k\in[i+1\ldots q-1]:LCP[k]>LCP[i]\}$.
\end{definition}
To simulate a traversal of a Suffix Tree on an Enhanced Suffix Array we require the child table. In order to perform the traversal we get an interval $l-$interval $[i..j]$ and a character $a\in \Sigma$ as input and returns the child interval $[l..r]$ of $[i..j]$ whose suffixes have the character $a$ at position $l$. Note that all the suffixes in $[l..r]$ share the same $l-$character prefix because $[l..r]$ is a subinterval of $[i..j]$. This process is performed in $O(|\Sigma|)$ time.\\
Once we have defined the resources used to index a Reference genome, we need to answer the question: Where are the MUMs of $R$ and $Q$ of some minimum length $L$? We show the algorithms used to answer this question using a Suffix Tree and a Enhanced Suffix Array.
\linesnumbered
\begin{algorithm}
  \dontprintsemicolon
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \SetKwData{R}{R}
  \SetKwData{Q}{Q}
  \SetKwData{ST}{ST}
  \SetKwData{Len}{L}
  \SetKwData{Length}{length}
  \SetKwData{Leaf}{leaf}
  \SetKwData{MUMs}{MUMs}
  \SetKwData{MUMcands}{MUMcands}
  \SetKwFunction{buildST}{buildST}
  \SetKwFunction{TraverseSuffixTree}{TraverseSuffixTree}
  \SetKwFunction{isLeafNode}{isLeafNode}
  \SetKwFunction{saveMUMcand}{saveMUMcand}
  \SetKwFunction{cleanMUMcand}{cleanMUMcand}
  \Input{\R, \Q, \Len}
  \Output{List of \MUMs of \Length$\geq$ \Len, with start position in \R and \Q and \Length}
  \Begin{
  \ST$\leftarrow$ \buildST{\R}\;
  \ForEach{position $i\in Q$}{
  \Length$\leftarrow$ \TraverseSuffixTree{$\Q[i]$,\ST}\;
    \If{\isLeafNode{$\Q[i]$}}{
    \tcc{Leaf saves the position of a suffix in ST.}\;
        \If{$\R[\Leaf-1]\neq \Q[i-1]$ and $\Length\geq L$}{
            \MUMcands$\leftarrow$ \saveMUMcand{$\R_{\Leaf}$,$i$,\Length}\;
        }
    }
  }
  \tcc{Get unique MUMs from list of MUM-candidates.}\;
  \MUMs$\leftarrow$ \cleanMUMcand{\MUMcands}
  }
  \caption{Search for MUMs in a Suffix Tree.}
\end{algorithm}
\linesnumbered
\begin{algorithm}
  \dontprintsemicolon
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \SetKwData{R}{R}
  \SetKwData{Q}{Q}
  \SetKwData{Len}{L}
  \SetKwData{End}{end}
  \SetKwData{inter}{interval}
  \SetKwData{n}{n}
  \SetKwData{vi}{i}
  \SetKwData{sa}{SA}
  \SetKwData{esa}{ESA}
  \SetKwData{isa}{ISA}
  \SetKwData{qF}{queryFound}
  \SetKwFunction{tra}{traverseSA}
  \SetKwFunction{saveMUMcand}{saveMUMcand}
  \SetKwFunction{cleanMUMcand}{cleanMUMcand}
  \SetKwFunction{bESA}{buildESA}
  \SetKwFunction{sufl}{suffixlink}
  \SetKwFunction{lfmax}{leftMaximal}
  \SetKwData{Length}{length}
  \SetKwData{MUMs}{MUMs}
  \Input{\R, \Q, \Len}
  \Output{List of \MUMs of \Length$\geq$ \Len, with start position in \R and \Q and \Length}
  \Begin{
  \esa$\leftarrow$ \bESA\;
  \While{\Q[\vi] $<$ \End} {
    \tcc{Traverse SA top down until mismatch or full string is matched.}\;
    \tra{\Q, \Q[i], \inter, \Q[\vi].length()}\;
    \If{\inter.depth $\leq$ 1} { 
       \inter.depth = 0; \inter.start = 0; \inter.end = \n-1; \vi++; continue; }
    \If{\inter.size() = 1 and \inter.depth $\geq$ \Len} {
      \If{\lfmax{\Q, \Q[\vi], \sa[\inter.start]}} {
            \saveMUMcand{\sa[\inter.start,\vi,\inter.depth}\;
      }
    }
    \Repeat{\inter.depth $>$ 0 and \inter.size()} {
      \inter.depth = \inter.depth-1\;
      \inter.start = \isa[\sa[\inter.start] + 1]\;  
      \inter.end = \isa[\sa[\inter.end] + 1]; 
      \vi++;
      \If{\inter.depth = 0 or \sufl{inter} = false} { \inter.depth = 0; \inter.start = 0; \inter.end = \n-1; break; }
    } 
  }
  }
  \caption{Search for MUMs in an Enhanced Suffix Array.}
\end{algorithm}
\section{Implementation}
The search for MUM between a Reference and Query genome has an important feature which may help us to parallelize these algorithms. Using a full-text index data structure to search for MUMs we find MUM candidates as we stream the Query genome against the data structure. That is a MUM candidate is a MUM which is not unique in both Reference and Query genome. We only know that a MUM candidate is unique in the Reference genome. To get a MUM we require to reach the end of Query genome to discard those MUMs candidates which are not unique in both Reference and Query genome, see Figure \ref{Whole-MUM}.\\ 
\begin{figure}[h]
\centering 
  \epsfig{file=Whole-MUM.eps, height=1in, width=2.5in}
\caption{To get a MUM, it requires an important feature its uniqueness. Uniqueness can only be found when a whole genome is checked.} 
\label{Whole-MUM} 
\end{figure}
If some part of it is only evaluated we could miss the rest of the genome. In other words, after finding MUMs within a chunk it is not possible to determine if the MUM found is or not a "unique" MUM, globally in the query genome,  because these MUMs are unique only in the chunk that has been read, the rest of the genome it is not known until all query genome has been read. In Figure \ref{Whole-MUM} is shown the consequences of using chunks for query genome.\\
Meanwhile we may speed up the MUM search we need to deal with the discard of MUM-candidates which are not a real MUM. So that, after finding all MUM-candidates for every thread we need to verify which of MUM-candidates are MUM. Therefore this phase of discarding MUM candidates must be performed always. However, the search for MUM candidates can be performed in any position of the Query genome and then apply the last phase to filter the MUMs. So that a very good choice of parallelization involves a data partition technique, see Figure \ref{phases}.\\
\begin{figure}[h] 
\centering 
  \psfig{file=Phases.ps, height=2in, width=3in}
\caption{Our approach is divided in three phases: Creation of Suffix Tree or Enhanced Suffix Array; Splitting query genome data (chunks) according to the number of available cores using 1 thread per core and parallel execution of the search for MUMs for every chunk, then every thread has its own list of MUM-candidates; and Get MUMs from list of MUM-candidates of all threads.}
  \label{phases}
\end{figure}
A data-level parallelism to search for MUMs requires to split the Query genome and stream each chunk against the full-text index data structure. This search is independent of each other chunk because the final stage to filter MUMs must be performed with a full Query genome and with chunks of Query genome is more obvious too. This approach is suitable to be performed in multi-core architectures because chunks can be assigned to each core and search for MUMs in the full-text index data structure which is stored in main memory.\\
There are two resources to improve with this approach: Memory and CPU usage. Memory usage can only be improved, within this approach, with multiple reads to the full-text index data structure, instead of one read at a time with a serial execution. CPU usage is really improved with multi-core architectures. Since a SPMD paradigm is used to solve the MUM-problem, we must tackle the issues which arise when using multi-core architectures.\\
The division of Query genome  was used using the paradigm of data-level parallelism which consists of a generation of chunks of a query sequence with a fixed size. The chunk size was computed with Query genome length divided by number of available threads.Chunk size is a performance factor because we need to have an ideal size to have a balanced workload among threads.\\
We evaluated two different full-text index data structures: a Suffix Tree and an Enhanced Suffix Array. We applied our approach, Figure \ref{phases}, by using OpenMP in the phase 2: search for MUMs with a static OpenMP schedule.\\
Phase one is the construction of the data structure: Suffix Tree or Enhanced Suffix Array; this phase is executed in a serial way. The second phase requires the parallel execution of the algorithm to search for MUMs, the first step in Phase 2 is the split of Query genome in as many chunks as available threads. The split defines the start and end position in Query genome which is held in main memory and shared by all threads. The chunk size is fixed according to the number of threads. The parallel search for MUMs gets a list of MUM-candidates which are ordered in each thread by its position in Query genome. Phase 3 is performed after all thread have finished its execution and it merges the lists of MUM-candidates and it is ordered by position in Query genome (this step is needed because the merge process may have unordered lists); this unique list is checked to discard those MUM-candidates which are not unique in the Query genome. This check is performed in a serial way.
\section{Results}
To verify that our approach, can have a better performance to search for MUMs of a Reference and Query genome we verify that output of MUMmer and our approach to check that they produce the same MUMs. This test was carried out in the following node:
\begin{itemize}
\item Hardware:  
\begin{itemize}
\item 2 Processor Intel(R) Xeon(R) E5645 @ 2.4GHz of 6 cores each one, 32KB L1 cache, 256KB L2 and 12MB L3 shared cache per socket.
\item RAM: 96 GB
\end{itemize} 
\item  Software: 
\begin{itemize}
\item gcc 4.7.0 with OpenMP support
%\item PAPI 5.0.1
\end{itemize}  
\end{itemize}
\begin{table}
\centering
\caption{List of Genomes used in experiments.}
\label{genomes}
\begin{tabular}{|c|l|l|l|} \hline
  & 1 & 2 & 3 \\ \hline
  Reference & 4.64 [Mbp] & 169 [Mbp] & 1031 [Mbp] \\ \hline
  Query & 5.5 [Mbp] & 167 [Mbp] & 1357 [Mbp] \\ 
  \hline
\end{tabular}
\end{table}
The main objective of these tests was to check the performance to search for MUMs in multi-core architectures by using OpenMP (threads). This performance involves the usage of Memory and CPU (execution time to search for MUMs).\\
One key aspect of the several tests deployed was to assure the execution of every thread in a single core, that is no other thread is competing for the same cache. Affinity is a requirement because we need to ensure the scalability of our proposal, without affinity even a number of threads below the number of cores might be in the same core. Affinity ensures us a proper use of performance in a multi-core architecture.\\
Times were collected during the execution of the experiments: construction time of data structure and execution time to search for mums with the function omp\_get\_wtime of OpenMP.\\
\subsection{Construction of Full-text index data structure}
This paper compares the performance of two data structures to search for MUMs in multi-core architectures, two requirements for these structures are: construction time and memory footprint. Full-text indexes allow fast access to substrings of any length, but they have a great memory and construction cost. This cost is affected by the type and implementation of the index data structure used. We compare the construction time for the set of genomes \ref{genomes}. In Figure \ref{fig:construction} is shown that a ESA has a lower construction time for all the Reference genomes. Since a full-text index data structure has to be build every time a search for MUMs is performed, a reduction in the construction phase in \ref{phases} allows us to improve the overall execution time.
\begin{figure}
  \centering
  \epsfig{file=construction.eps, width=2.5in,height=1.5in}
  \caption{Construction of Suffix Tree and Enhanced Suffix Array for several genomes sizes. Our approach saves the whole Reference genome indexed by a Suffix Tree (ST) or an Enhanced Suffix Array (ESA) in main memory.}
  \label{fig:construction}
 \end{figure}  
 \subsection{Search for MUMs in multi-core architectures}
%Meanwhile the memory footprint shown in Figure \ref{fig:ram} gives a better memory usage for the ESA, 
%\begin{figure}
%  \centering
%  \epsfig{file=ecoli-RAM.eps, width=3in,height=2in}
%  \caption{Memory footprint for a Reference genome of size 4.64 [Mbp].}
%  Speedup of our approach to search MUMs in multi-core architectures with OpenMP.}
%  \label{fig:speedup}
% \end{figure}  
Our main goal is to show that we can use multi-core architectures to search for MUMs. In figure \ref{fig:speedup} shows the speedup for the parallelization of searching for MUMs for a minimum length of 20[bp]. Moreover from this Figure \ref{fig:speedup} we can conclude that we got a near linear speedup with 12 threads, which is the maximum number of cores, with the set 1 of Table \ref{genomes} using ST and ESA. Then there is a reduction in the linear speedup because we are using 2 threads per core and this causes a degradation in the phase of searching for MUMs. With the set 2 of Table \ref{genomes} there is a degradation of speedup with 12 and 24 threads in ST and ESA. With the set 3 of Table \ref{genomes} the speedup of ESA is better than the ST, although not very close to a linear speedup with 12 and 24 threads.
\begin{figure}[h]
  \centering
  \epsfig{file=speedup-MUM.eps, width=2.5in,height=1.5in}
  \caption{Speedup of our approach to search MUMs in multi-core architectures with OpenMP in ST and ESA.}
  \label{fig:speedup}
\end{figure}  
Now we focus in the experiment to search for MUMs of minimum length 20[bp]. Our goal is to get the best performance of a multi-core architecture while searching for MUMs.
\subsubsection{EcoliK12 vs. EcoliO157H7}
The set 1 in Table \ref{genomes} was used to search for MUMs in a ST and ESA. In Figure \ref{fig:ecoli-mum} we show that both data structures have a similar search time.
\begin{figure}[h]
  \centering
  \epsfig{file=ecoli-MUM.eps, width=2.5in,height=1.5in}
  \caption{Search for MUMs time for Ecolik12 and EcoliO157H7 in multi-core architectures with ST and ESA.}
  \label{fig:ecoli-mum}
\end{figure}  
However, the space consumption in Figure \ref{fig:ecoli-ram} shows that ESA has a better memory footprint.
\begin{figure}[h]
  \centering
  \epsfig{file=ecoli-RAM.eps, width=2.5in,height=1.5in}
  \caption{RAM consumption to search for MUMs for Ecolik12 and EcoliO157H7 in multi-core architectures with ST and ESA.}
  \label{fig:ecoli-ram}
\end{figure}  
This first experiment shows that it is possible to search for MUMs with two different full-text index data structures with the same search time but with a lower memory consumption for ESA.
\subsubsection{D.melanogaster vs. D.pseudoobscura}
The set 2 in Table \ref{genomes} increases the genome size and we show in Figure \ref{fig:fly-mum} that ST and ESA have small differences in search time.
\begin{figure}[h]
  \centering
  \epsfig{file=fly-MUM.eps, width=2.5in,height=1.5in}
  \caption{Search for MUMs time for D.melanogaster and D.pseudoobscura in multi-core architectures with ST and ESA.}
  \label{fig:fly-mum}
\end{figure}  
On the other hand, the space consumption is almost constant in both data structures. However, again ESA has a better usage of memory. The reduction in ESA is near to the half of the ST, see Figure \ref{fig:fly-ram}.
\begin{figure}[h]
  \centering
  \epsfig{file=fly-RAM.eps, width=2.5in,height=1.5in}
  \caption{RAM consumption to search for MUMs for D.melanogaster and D.pseudoobscura in multi-core architectures with ST and ESA.}
  \label{fig:fly-ram}
\end{figure}  
\subsubsection{Chicken vs. Zebrafish}
The set 3 in Table \ref{genomes} have genomes of Gbp size and we show in Figure \ref{fig:chicken-mum} that an execution with one thread has a better performance in search time in ST over SA. However, when using multi-core architecture the search time is almost the same. So that the choice between a ST or ESA depends on the use of multi-core architectures, ST is more suitable in a serial way.
\begin{figure}[h]
  \centering
  \epsfig{file=chicken-MUM.eps, width=2.5in,height=1.5in}
  \caption{Search for MUMs time for Chicken and Zebrafish in multi-core architectures with ST and ESA.}
  \label{fig:chicken-mum}
\end{figure}  
In order to understand which full-text index data structure (ST, ESA) use to search for MUMs we check the memory footprint in Figure \ref{fig:chicken-ram}. The ESA has a better use of memory with the same search time.
\begin{figure}[h]
  \centering
  \epsfig{file=chicken-RAM.eps, width=2.5in,height=1.5in}
  \caption{RAM consumption to search for MUMs for Chicken and Zebrafish in multi-core architectures with ST and ESA.}
  \label{fig:chicken-ram}
\end{figure}  
\section{Conclusions}
This paper presents an evaluation of performance to search MUMs of a query and reference genome in multi-core architectures with OpenMP in a Suffix Tree and an Enhanced Suffix Array. The search for MUMs is performed in a Suffix Tree or an Enhanced Suffix Array and the list of MUMs can help in the process of Whole Genome Alignment. The results shows that MUM-proble-problem can be solved with a ST or ESA and with the use of a multi-core architecture. Although we got a poor speedup with big genomes, there is a reduction in memory usage with an Enhanced Suffix Array over a Suffix Tree. We have a different data structure which provides the same functionality of a Suffix Tree with less use of memory.\\
Improvements involve a better use of CPU when we have more than one thread per core. From the results obtained we conclude that an Enhanced Suffix Array is suitable to solve the MUM-problem. To improve the performance of our approach the following proposals may be used:
\begin{itemize}
  \item Prefetching: this may work because we know in advance what intervals to look for in ESA and Query genome. 
  \item Data cache management: this is an obvious consequence of previous bullet because we may need to store the interval of ESA in some cache-level of processor.
\end{itemize}
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This work was supported by grant from Ejecuci\'on eficiente de aplicaciones multidisciplinares: nuevos desaf\'ios en la era multi/many core, with reference TIN2011-28689-C02-01.
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{mum-mc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\balancecolumns
% That's all folks!
\end{document}
